{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data Extraction #####\n",
    "\n",
    "import re\n",
    "import docx2txt\n",
    "from docx import Document\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "############################ for generaliazation #######################################\n",
    "\n",
    "text_realted_dictionary = {}\n",
    "Main_heading_list = [\"hobbies\",\"Skill\",\"education\",\"work\",\"experience\",\"certification\",\"affiliation\",\"projects\",\n",
    "                    \"researches\",\"publication\",\"activities\",\"information\",\"interests\",\"career\",\"qualification\",\"academic\",\"expertise\",\"objectives\",\n",
    "                     \"training\",\"volunteering\",\"Languages\",\"studies\",\"miscellaneous\",\"education\",\"employment\",\"profile\",\n",
    "                     \"summary\",\"jobs\",\"expertise\",\"Competencies\",\"Operating\",\"ICT\"]\n",
    "languages_used = [\"Spanish\",\"English\",\"Hindi\",\"Arabic\",\"Portuguese\",\"Bengali\",\"Russian\",\"Japanese\",\"Punjabi\",\"German\",\n",
    "                  \"Javanese\",\"Malay\",\"Telugu\",\"Vietnamese\",\"Korean\",\"French\",\"Marathi\",\"Tamil\",\"Urdu\",\"Turkish\",\"Italian\",\n",
    "                  \"Thai\",\"Gujarati\",\"Jin\",\"Southern Min\" ,\"Persian\",\"Polish\",\"Pashto\",\"Kannada\",\"Xiang\",\"Malayalam\",\n",
    "                  \"Sundanese\",\"Hausa\",\"Odia\",\"Burmese\",\"Hakka\",\"Ukrainian\",\"Bhojpuri\",\"Tagalog\",\"Yoruba\",\"Maithili\",\n",
    "                  \"Uzbek\",\"Sindhi\",\"Amharic\",\"Fula\",\"Romanian\",\"Oromo\",\"Igbo\",\"Azerbaijani\",\"Awadhi\",\"Gan\",\"Cebuano\",\"Dutch\"]\n",
    "Main_heading_after_stemming = []\n",
    "Final_heading = []\n",
    "Data_related_to_headings =[]\n",
    "\n",
    "templete_dictionary={}\n",
    "extraction_dictionary={}\n",
    "\n",
    "####################### Data Ectraction varaibles ############################################\n",
    "\n",
    "Mainheadertittle = \"\"                                   # Main header heading is present in this varaiable\n",
    "MainFootertittle = \"\"                                   # Main footer heading is present in this varaiable \n",
    "\n",
    "####################### Docx2 Varaiables #############################################\n",
    "\n",
    "fullText_doc2 = []                                      # Main text List of Docx2\n",
    "\n",
    "############################### General Coding ################################################\n",
    "\n",
    "def Words_adjustments(word):                                # words_adjustments is basically removing the tab and spaces \n",
    "    word_list = word.split()\n",
    "    new_word = \"\"\n",
    "    for i in word_list:\n",
    "        new_word = new_word + i + \" \"\n",
    "    return (new_word.strip())\n",
    "\n",
    "def matching_function(word,i):                             # This function is matching the heads and words  \n",
    "    Main_heading_after_stemming = Main_heading_list_stemming_function(Main_heading_list)\n",
    "    if word.lower() in Main_heading_after_stemming:\n",
    "        Final_heading.append(i)\n",
    "        Data_related_to_headings.append(0)\n",
    "        return True\n",
    "    \n",
    "        \n",
    "        \n",
    "def heading_finding_pre_steps(lists,heading_length):                   # Limited the searching of headings Step-1 in which len 5 is included\n",
    "    for i in lists:\n",
    "        Second_list = i.split()                         # second_list is just Heading finding in limited searches\n",
    "  \n",
    "        if len(Second_list) <= heading_length:\n",
    "            if len(Second_list) != 0:\n",
    "                for j in Second_list:\n",
    "                    word = normal_stemming_function(j)\n",
    "                    Flag = matching_function(word,i)\n",
    "                    if Flag:\n",
    "                        break\n",
    "                if Flag:                                              #Checking that if it is not heading then it means\n",
    "                    continue                                          #that is going to be detial of certain heading\n",
    "                else:\n",
    "                    Data_related_to_headings.append(i)\n",
    "\n",
    "        else:\n",
    "            Data_related_to_headings.append(i)                      #if it is not going to len related to heading then\n",
    "                                                                    #it is detail of cetain heading\n",
    "    return Final_heading\n",
    "            \n",
    "            \n",
    "def Main_heading_list_stemming_function(lists):           # Main Heading by defult stemmming process \n",
    "    porter = PorterStemmer()\n",
    "    lancaster=LancasterStemmer()\n",
    "    length = len(lists)\n",
    "    counter = 0\n",
    "    while(length > counter):\n",
    "        Main_heading_after_stemming.append(porter.stem(lists[counter]))\n",
    "        counter = counter + 1\n",
    "    return (Main_heading_after_stemming)\n",
    "\n",
    "\n",
    "def normal_stemming_function(word):                     # Words stemming \n",
    "    porter = PorterStemmer()\n",
    "    lancaster=LancasterStemmer()\n",
    "    return porter.stem(word)\n",
    "\n",
    "def now_printing_all_the_data_related_it(Data_related_to_headings,Final_heading):\n",
    "    for i in Final_heading:\n",
    "        text_realted_dictionary[i] = \"\"\n",
    "        \n",
    "    Text=[] \n",
    "    counter = 0\n",
    "    heading=\"\"\n",
    "    text_docx=\"\"\n",
    "    for i in Data_related_to_headings:\n",
    "\n",
    "        if i ==0:  \n",
    "            if counter > 0:\n",
    "                Text.append(text_docx)\n",
    "                text_docx =\"\"\n",
    "            counter = counter + 1;\n",
    "        else:\n",
    "            text_docx = text_docx + i + \"\\n\"\n",
    "    Text.append(text_docx)\n",
    "    return Text\n",
    "\n",
    "#################################################### Major Calling Function ############################################\n",
    "\n",
    "def main_function(path,heading_length):\n",
    "    text_realted_dictionary = {}\n",
    "    Text = []\n",
    "    heading=[]\n",
    "    del  Final_heading[:]\n",
    "    del Main_heading_after_stemming[:]\n",
    "    del Data_related_to_headings[:]\n",
    "    del fullText_doc2[:]\n",
    "    MY_TEXT = docx2txt.process(path)              #Reading the file viva docx2txt libaray \n",
    "    Text =MY_TEXT.split(\"\\n\")                                #Split the whole text at new line character\n",
    "\n",
    "    Mainheadertittle = Finding_header_()                    # checking the header is avaiable or not \n",
    "    MainFootertittle=  Finding_footer_()                    # checking the footer is avaiable or not\n",
    "    \n",
    "                 # Bring the data is proper fromat before doing process on it \n",
    "    for i in Text:\n",
    "        if len(i) >1:\n",
    "            if i != Mainheadertittle:\n",
    "                if i != MainFootertittle:\n",
    "                    fullText_doc2.append(Words_adjustments(i))   # Words_adjustments is Basically removing tab and space in the end\n",
    "    heading = heading_finding_pre_steps(fullText_doc2,heading_length)\n",
    "    without_duplicate = set(Final_heading)\n",
    "    Text = now_printing_all_the_data_related_it(Data_related_to_headings,Final_heading)\n",
    "\n",
    "    counter=0;\n",
    "    for i in Final_heading:\n",
    "        text_realted_dictionary[i.lower()] = Text[counter]\n",
    "        counter = counter + 1\n",
    "    return heading[:],text_realted_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data insertion ######\n",
    "from docx import Document\n",
    "\n",
    "# Data Extraction #####\n",
    "import re\n",
    "import docx2txt\n",
    "from docx import Document\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "import os\n",
    "\n",
    "def match_date(date):\n",
    "    \n",
    "    match = re.search('\\d{4}-\\d{2}-\\d{2}', date)\n",
    "    match2 = re.search('\\d{4}-\\d{2}', date)\n",
    "    match3 = re.search('^(19|[2-9][0-9])\\d{2}$',date)\n",
    "    regEx = r'(?:\\d{1,2}[-/th|st|nd|rd\\s]*)?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)?[a-z\\s,.]*(?:\\d{1,2}[-/th|st|nd|rd)\\s,]*)+(?:\\d{2,4})+'\n",
    "    match4 = re.search(regEx,date)\n",
    "    \n",
    "    if match or match2 or match3 or match4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def matching_heading_between_both(data_extraction_heading,templete_heading):\n",
    "    \n",
    "    data_extraction_heading=[x.lower() for x in data_extraction_heading]\n",
    "    templete_heading=[x.lower() for x in templete_heading]\n",
    "\n",
    "    matching_heading =[]\n",
    "    dic_heading = []\n",
    "\n",
    "    connection_word=[\"the\",\"and\",\"an\",\"a\",\"is\",\"cont\",\"of\"]\n",
    "    flag = False\n",
    "\n",
    "    for heading_extraction in data_extraction_heading:\n",
    "        h_e_split=heading_extraction.split()\n",
    "        for i in h_e_split:\n",
    "            if i in connection_word:\n",
    "                continue \n",
    "            else:\n",
    "                for heading_cv in templete_heading:\n",
    "                    h_c_split = heading_cv.split()\n",
    "                    for j in h_c_split:\n",
    "                        if normal_stemming_function(j) == normal_stemming_function(i):\n",
    "                            matching_heading.append(heading_cv.lower())\n",
    "                            dic_heading.append(heading_extraction.lower())\n",
    "                            flag = True\n",
    "                            break\n",
    "\n",
    "                    if flag == True:\n",
    "                        break\n",
    "                if flag == True:\n",
    "                    flag = False\n",
    "                    break\n",
    "    return matching_heading,dic_heading\n",
    "\n",
    "###### Main Insertion Wala Part Tayyab ##########\n",
    "def add_para_language(data,doc):\n",
    "    combining_data=\"\"\n",
    "    spliting_list = data.split(\"\\n\")\n",
    "    for i in spliting_list:\n",
    "        for j in languages_used:\n",
    "            if j.lower() in i.lower(): \n",
    "                combining_data = combining_data +\"•  \"+ i + \"\\n\"\n",
    "                break\n",
    "\n",
    "    data = combining_data\n",
    "    combining_data=\"\"\n",
    "    return doc.add_paragraph(data) # adding the paragraph at the end\n",
    "def add_para(data,doc):\n",
    "    combining_data=\"\"\n",
    "    spliting_list = data.split(\"\\n\")\n",
    "    for i in spliting_list:\n",
    "        if  (match_date(i)):\n",
    "            combining_data = combining_data + \"\\n\"\n",
    "            combining_data = combining_data+\"\\t\"+\"==>  \"+i+\"\\n\"\n",
    "            combining_data = combining_data + \"\\n\"\n",
    "        else:\n",
    "            combining_data = combining_data +\"•  \"+ i + \"\\n\"\n",
    "\n",
    "    data = combining_data\n",
    "    combining_data=\"\"\n",
    "    return doc.add_paragraph(data) # adding the paragraph at the end\n",
    "\n",
    "def move_para(document,matching_heading,dic_heading):\n",
    "    \n",
    "    for paragraph in document.paragraphs: #Iterating through each paragraph and checking when the paragraph text is equal\n",
    "                                            # to headings of template this means now there is heading in paragraph variable\n",
    "        if (paragraph.text).lower() in matching_heading:\n",
    "            if ((paragraph.text).lower()) == \"language\" or ((paragraph.text).lower()) == \"languages\":\n",
    "                indexing = matching_heading.index(paragraph.text.lower())\n",
    "                para = add_para_language(extraction_dictionary[dic_heading[indexing].lower()],document)      \n",
    "                p = para._p\n",
    "                paragraph._p.addnext(p)\n",
    "            else:\n",
    "                indexing = matching_heading.index(paragraph.text.lower())\n",
    "                para = add_para(extraction_dictionary[dic_heading[indexing].lower()],document)      \n",
    "                p = para._p\n",
    "                paragraph._p.addnext(p)\n",
    "            \n",
    "        elif (paragraph.text.strip()).lower in matching_heading: # check for a missed heading\n",
    "            para = add_para(extraction_dictionary[paragraph.text.strip()])\n",
    "            p = para._p            \n",
    "            paragraph._p.addnext(p)\n",
    "            \n",
    "def Start_calling_from_here(filename,data_extracion,templete_heading):\n",
    "    print(data_extracion)\n",
    "    \n",
    "    matching_heading,dic_heading = matching_heading_between_both(data_extraction_heading,templete_heading)\n",
    "    doc = Document(filename)     \n",
    "    move_para(doc,matching_heading,dic_heading) #sending data and document hanlde doc to function\n",
    "\n",
    "    desktop = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "    \n",
    "    desktop = desktop + \"\\\\\"\n",
    "    file_path = desktop + \"Cv creation.docx\"\n",
    "    from pathlib import Path\n",
    "    counter = 1\n",
    "    while(True):\n",
    "        my_file = Path(file_path)\n",
    "        if my_file.is_file():\n",
    "            file_path = desktop + \"Cv Creation\" + str(counter) +\".docx\" \n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            doc.save(file_path)\n",
    "            break\n",
    "    return(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################### complete Qui\n",
    "\n",
    "from docx import Document\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import tkinter.font as font\n",
    "from tkinter import messagebox\n",
    "\n",
    "rootname = Tk()\n",
    "\n",
    "rootname.configure(background='black')\n",
    "rootname.geometry(\"700x300\")\n",
    "\n",
    "\n",
    "heading_length_extraction =3\n",
    "heading_length_templete = 3\n",
    "templete =\"\"\n",
    "Extraction =\"\"\n",
    "data_extraction_heading = []\n",
    "templete_heading = []\n",
    "\n",
    "def working_started():\n",
    "    rootname.destroy()\n",
    "    root1=Tk()\n",
    "    root1.title(\"Cv style\")\n",
    "    root1.configure(background='black')\n",
    "    root1.geometry(\"400x500\")\n",
    "\n",
    "    myFont_label = font.Font(size=15)\n",
    "    myFont_button = font.Font(size=12)\n",
    "    \n",
    "    Heading_label =Label(root1,text=\"Curriculum Vitae Based Application\",fg=\"white\",bg=\"Black\")\n",
    "    Heading_label['font'] = myFont_label\n",
    "    Heading_label.pack()\n",
    "\n",
    "    Data_extraction_button = Button(root1,text=\"Select Cv for Data\",fg=\"white\",bg=\"Green\",width=20,\n",
    "                                    height=3,command=getting_path_for_extraction)\n",
    "    Data_extraction_button['font'] = myFont_button\n",
    "    Data_extraction_button.pack(pady=30)\n",
    "\n",
    "    Cv_templete = Button(root1,text=\"Select Cv for Data\",fg=\"white\",bg=\"Green\",width=20,\n",
    "                                    height=3,command=getting_path_for_templete)\n",
    "    Cv_templete['font'] = myFont_button\n",
    "    Cv_templete.pack(pady=20)\n",
    "\n",
    "\n",
    "    Heading_length_getting = Button(root1,text=\"Change Heading length\",command=Clickme,fg=\"white\",bg=\"Green\",width=20,height=3)\n",
    "    Heading_length_getting['font'] = myFont_button\n",
    "    Heading_length_getting.pack(pady=20)\n",
    "\n",
    "    Stated = Button(root1,text=\"Get Stated\",fg=\"black\",bg=\"Red\",width=20,height=3,command=calling_function)\n",
    "    Stated['font'] = myFont_button\n",
    "    Stated.pack(pady=20)\n",
    "    root1.mainloop()\n",
    "\n",
    "def Click_to_get1(horizontal,top):\n",
    "    global heading_length_templete\n",
    "    heading_length_templete =horizontal.get()\n",
    "    messagebox.showinfo(\"Lenght of Heading is increase\",'Length of heading is' + str(heading_length_templete))\n",
    "\n",
    "def Click_to_get(horizontal,top):\n",
    "    global heading_length_extraction\n",
    "    heading_length_extraction =horizontal.get()\n",
    "    messagebox.showinfo(\"Lenght of Heading is increase\",'Length of heading is' + str(heading_length_templete))\n",
    "\n",
    "def Clickme():\n",
    "    top = Toplevel()\n",
    "    top.geometry(\"400x300\")\n",
    "    top.title(\"Heading Length\")\n",
    "    top.configure(background='black')\n",
    "    label = Label(top,text=\"Changing Heading Length\",fg=\"white\",bg=\"Black\")\n",
    "    label['font'] = myFont_label\n",
    "    label.pack(pady=10)\n",
    "    horizontal =Scale(top,from_=1,to=5,orient=HORIZONTAL)\n",
    "    horizontal.pack()\n",
    "    button = Button(top,text=\"Change Heading length of data Getting\",command=lambda:Click_to_get(horizontal,top),fg=\"white\",bg=\"Green\")\n",
    "    button.pack(pady=20)\n",
    "    horizontal1 =Scale(top,from_=1,to=5,orient=HORIZONTAL)\n",
    "    \n",
    "    horizontal1.pack()\n",
    "    button2 = Button(top,text=\"Change Heading length of templete\",command=lambda:Click_to_get1(horizontal1,top),fg=\"white\",bg=\"Green\")\n",
    "    button2.pack(pady=20)\n",
    "    \n",
    "def getting_path_for_templete():\n",
    "    global templete\n",
    "    global templete_heading\n",
    "    global templete_dictionary\n",
    "    Frame.FileTemplete= filedialog.askopenfilename(initialdir=\"/img\",title=\"Select A file\",filetypes=((\"docx files\",\"*.docx\"),(\"all file\",\"*.*\")))\n",
    "    templete= Frame.FileTemplete\n",
    "    templete_heading,templete_dictionary = main_function(templete,heading_length_templete)\n",
    "    \n",
    "    \n",
    "def getting_path_for_extraction():\n",
    "    global Extraction\n",
    "    global data_extraction_heading\n",
    "    global extraction_dictionary\n",
    "    Frame.FileExtraction= filedialog.askopenfilename(initialdir=\"/img\",title=\"Select A file\",filetypes=((\"docx files\",\"*.docx\"),(\"all file\",\"*.*\")))\n",
    "    Extraction=Frame.FileExtraction\n",
    "    data_extraction_heading,extraction_dictionary = main_function(Extraction,heading_length_extraction)\n",
    "def calling_function():\n",
    "    global templete\n",
    "    global data_extraction_heading\n",
    "    global extraction_dictionary\n",
    "    global templete_heading\n",
    "    global templete_dictionary\n",
    "    if Extraction == \"\" or templete == \"\":\n",
    "        messagebox.showinfo(\"File Probelm\",\"One file is missing either Data extraction File or Templete File\")\n",
    "    else:\n",
    "        data_extraction_heading,extraction_dictionary = main_function(Extraction,heading_length_extraction)\n",
    "        templete_heading,templete_dictionary = main_function(templete,heading_length_templete)\n",
    "        file_path=Start_calling_from_here(templete,data_extraction_heading,templete_heading)\n",
    "        messagebox.showinfo(\"File path where file is saved\",file_path)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "myFont_label = font.Font(size=15)\n",
    "myFont_button = font.Font(size=12)\n",
    "    \n",
    "Heading_label =Label(rootname,text=\"Rules of Curriculum Vitae Based Application\",fg=\"Red\",bg=\"Black\")\n",
    "Heading_label['font'] = myFont_label\n",
    "Heading_label.pack()\n",
    "\n",
    "Rule1 = Label(rootname,text=\"1) If you want to change the heading lengths.Do it before selecting files\",fg=\"white\",bg=\"Black\")\n",
    "Rule1['font'] = myFont_label\n",
    "Rule1.pack()\n",
    "\n",
    "Rule2 = Label(rootname,text=\"2)If extra Heading came decreses the length of heading\" ,fg=\"white\",bg=\"Black\")\n",
    "Rule2['font'] = myFont_label\n",
    "Rule2.pack()\n",
    "\n",
    "Rule3 = Label(rootname,text=\"3)If some heading is missing increase the length of heading\",fg=\"white\",bg=\"Black\")\n",
    "Rule3['font'] = myFont_label\n",
    "Rule3.pack()\n",
    "\n",
    "Rule4 = Label(rootname,text=\"4) By heading extra and some means if it present in the data extraction file \" ,fg=\"white\",bg=\"Black\")\n",
    "Rule4['font'] = myFont_label\n",
    "Rule4.pack()\n",
    "\n",
    "Rule4 = Label(rootname,text=\" and not show in result file then these functionality is used\" ,fg=\"white\",bg=\"Black\")\n",
    "Rule4['font'] = myFont_label\n",
    "Rule4.pack()\n",
    "\n",
    "Rule4 = Label(rootname,text=\"5)File is save on you Desktop with name Cv Creation\" ,fg=\"white\",bg=\"Black\")\n",
    "Rule4['font'] = myFont_label\n",
    "Rule4.pack()\n",
    "\n",
    "\n",
    "Stated1 = Button(rootname,text=\"ok,Get Stated\",fg=\"black\",bg=\"Green\",width=20,height=2,command=working_started)\n",
    "Stated1['font'] = myFont_button\n",
    "Stated1.pack(pady=20)\n",
    "rootname.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
